{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from softtek_llm.chatbot import Chatbot\n",
    "from softtek_llm.models import OpenAI\n",
    "from softtek_llm.cache import Cache\n",
    "from softtek_llm.vectorStores import PineconeVectorStore\n",
    "from softtek_llm.embeddings import OpenAIEmbeddings\n",
    "from softtek_llm.schemas import Filter\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if OPENAI_API_KEY is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in .env file\")\n",
    "\n",
    "OPENAI_API_BASE = os.getenv(\"OPENAI_API_BASE\")\n",
    "if OPENAI_API_BASE is None:\n",
    "    raise ValueError(\"OPENAI_API_BASE not found in .env file\")\n",
    "\n",
    "OPENAI_EMBEDDINGS_MODEL_NAME = os.getenv(\"OPENAI_EMBEDDINGS_MODEL_NAME\")\n",
    "if OPENAI_EMBEDDINGS_MODEL_NAME is None:\n",
    "    raise ValueError(\"OPENAI_EMBEDDINGS_MODEL_NAME not found in .env file\")\n",
    "\n",
    "OPENAI_CHAT_MODEL_NAME = os.getenv(\"OPENAI_CHAT_MODEL_NAME\")\n",
    "if OPENAI_CHAT_MODEL_NAME is None:\n",
    "    raise ValueError(\"OPENAI_CHAT_MODEL_NAME not found in .env file\")\n",
    "    #Se configura nombre de variable apy_key\n",
    "PINECONE_API_KEY = os.getenv(\"api_key\")\n",
    "if PINECONE_API_KEY is None:\n",
    "    raise ValueError(\"PINECONE_API_KEY not found in .env file\")\n",
    "#Se configura nombre de variable environment\n",
    "PINECONE_ENVIRONMENT = os.getenv(\"environment\")\n",
    "if PINECONE_ENVIRONMENT is None:\n",
    "    raise ValueError(\"PINECONE_ENVIRONMENT not found in .env file\")\n",
    "#Se configura nombre de variable index\n",
    "PINECONE_INDEX_NAME = os.getenv(\"index\")\n",
    "if PINECONE_INDEX_NAME is None:\n",
    "    raise ValueError(\"PINECONE_INDEX_NAME not found in .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PineconeVectorStore(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENVIRONMENT,\n",
    "    index_name=PINECONE_INDEX_NAME,\n",
    ")\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model_name=OPENAI_EMBEDDINGS_MODEL_NAME,\n",
    "    api_type=\"azure\",\n",
    "    api_base=OPENAI_API_BASE,\n",
    ")\n",
    "cache = Cache(\n",
    "    vector_store=vector_store,\n",
    "    embeddings_model=embeddings_model,\n",
    ")\n",
    "model = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model_name=OPENAI_CHAT_MODEL_NAME,\n",
    "    api_type=\"azure\",\n",
    "    api_base=OPENAI_API_BASE,\n",
    "    verbose=True,\n",
    ")\n",
    "filters = [\n",
    "    Filter(\n",
    "        type=\"DENY\",\n",
    "        case=\"ANYTHING about the Titanic. YOU CANNOT talk about the Titanic AT ALL.\",\n",
    "    )\n",
    "]\n",
    "chatbot = Chatbot(\n",
    "    model=model,\n",
    "    description=\"You are a very helpful and polite chatbot\",\n",
    "    filters=filters,\n",
    "    cache=cache,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revision prompt: Considering this context:\n",
      "\t- user: When did the Titanic sink?\n",
      "\t- user: Hello! My name is Jeff.\n",
      "\t- assistant: Hello again, Jeff! How can I assist you today?\n",
      "\n",
      "Please review the prompt below and answer with \"yes\" if it adheres to the rules or \"no\" if it violates any of the rules.\n",
      "Rules:\n",
      "\t- DENY: ANYTHING about the Titanic. YOU CANNOT talk about the Titanic AT ALL.\n",
      "\n",
      "Prompt:\n",
      "Hello! My name is Jeff.\n",
      "Memory: [{'role': 'system', 'content': \"As a prompt reviser, your role is to determine whether the given prompt respects the rules provided below. You can only respond with 'yes' or 'no.' The rules are absolute, meaning that if any of them are not respected, the prompt is considered invalid.\"}, {'role': 'system', 'content': \"only respond with 'yes' or 'no'\"}, {'role': 'user', 'content': 'Considering this context:\\n\\t- user: When did the Titanic sink?\\n\\t- user: Hello! My name is Jeff.\\n\\t- assistant: Hello again, Jeff! How can I assist you today?\\n\\nPlease review the prompt below and answer with \"yes\" if it adheres to the rules or \"no\" if it violates any of the rules.\\nRules:\\n\\t- DENY: ANYTHING about the Titanic. YOU CANNOT talk about the Titanic AT ALL.\\n\\nPrompt:\\nHello! My name is Jeff.'}]\n",
      "Memory: [{'role': 'system', 'content': 'You are a very helpful and polite chatbot'}, {'role': 'assistant', 'content': \"Hello Jeff! It's a pleasure to meet you. How can I assist you today?\"}, {'role': 'user', 'content': 'What is my name?'}, {'role': 'user', 'content': 'Hello! My name is Jeff.'}, {'role': 'assistant', 'content': 'Hello Jeff! How can I assist you today?'}, {'role': 'user', 'content': 'What is my name?'}, {'role': 'assistant', 'content': 'Your name is Jeff.'}, {'role': 'user', 'content': 'When did the Titanic sink?'}, {'role': 'user', 'content': 'Hello! My name is Jeff.'}, {'role': 'assistant', 'content': 'Hello again, Jeff! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! My name is Jeff.'}]\n"
     ]
    }
   ],
   "source": [
    "response = chatbot.chat(\n",
    "    \"Hello! My name is Jeff.\",\n",
    "    print_cache_score=True\n",
    "    #se elimina namespace\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(message=Message(role='assistant', content='Hello Jeff! How can I assist you today?'), created=1695515859, latency=454, from_cache=False, model='gpt-35-turbo-16k', usage=Usage(prompt_tokens=80, completion_tokens=10, total_tokens=90), additional_kwargs={})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revision prompt: Considering this context:\n",
      "\t- user: What is my name?\n",
      "\t- user: Hello! My name is Jeff.\n",
      "\t- assistant: Hello Jeff! How can I assist you today?\n",
      "\n",
      "Please review the prompt below and answer with \"yes\" if it adheres to the rules or \"no\" if it violates any of the rules.\n",
      "Rules:\n",
      "\t- DENY: ANYTHING about the Titanic. YOU CANNOT talk about the Titanic AT ALL.\n",
      "\n",
      "Prompt:\n",
      "What is my name?\n",
      "Memory: [{'role': 'system', 'content': \"As a prompt reviser, your role is to determine whether the given prompt respects the rules provided below. You can only respond with 'yes' or 'no.' The rules are absolute, meaning that if any of them are not respected, the prompt is considered invalid.\"}, {'role': 'system', 'content': \"only respond with 'yes' or 'no'\"}, {'role': 'user', 'content': 'Considering this context:\\n\\t- user: What is my name?\\n\\t- user: Hello! My name is Jeff.\\n\\t- assistant: Hello Jeff! How can I assist you today?\\n\\nPlease review the prompt below and answer with \"yes\" if it adheres to the rules or \"no\" if it violates any of the rules.\\nRules:\\n\\t- DENY: ANYTHING about the Titanic. YOU CANNOT talk about the Titanic AT ALL.\\n\\nPrompt:\\nWhat is my name?'}]\n",
      "Memory: [{'role': 'system', 'content': 'You are a very helpful and polite chatbot'}, {'role': 'user', 'content': 'Hello! My name is Jeff.'}, {'role': 'user', 'content': 'Hello! My name is Jeff.'}, {'role': 'assistant', 'content': \"Hello Jeff! It's a pleasure to meet you. How can I assist you today?\"}, {'role': 'user', 'content': 'What is my name?'}, {'role': 'user', 'content': 'Hello! My name is Jeff.'}, {'role': 'assistant', 'content': 'Hello Jeff! How can I assist you today?'}, {'role': 'user', 'content': 'What is my name?'}]\n"
     ]
    }
   ],
   "source": [
    "response = chatbot.chat(\n",
    "    \"What is my name?\",\n",
    "    print_cache_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(message=Message(role='assistant', content='Your name is Jeff.'), created=1695515860, latency=319, from_cache=False, model='gpt-35-turbo-16k', usage=Usage(prompt_tokens=103, completion_tokens=5, total_tokens=108), additional_kwargs={})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revision prompt: Considering this context:\n",
      "\t- assistant: Hello again, Jeff! How can I assist you today?\n",
      "\t- user: Hello! My name is Jeff.\n",
      "\t- assistant: Hello, Jeff! How can I assist you today?\n",
      "\n",
      "Please review the prompt below and answer with \"yes\" if it adheres to the rules or \"no\" if it violates any of the rules.\n",
      "Rules:\n",
      "\t- DENY: ANYTHING about the Titanic. YOU CANNOT talk about the Titanic AT ALL.\n",
      "\n",
      "Prompt:\n",
      "When did the Titanic sink?\n",
      "Memory: [{'role': 'system', 'content': \"As a prompt reviser, your role is to determine whether the given prompt respects the rules provided below. You can only respond with 'yes' or 'no.' The rules are absolute, meaning that if any of them are not respected, the prompt is considered invalid.\"}, {'role': 'system', 'content': \"only respond with 'yes' or 'no'\"}, {'role': 'user', 'content': 'Considering this context:\\n\\t- assistant: Hello again, Jeff! How can I assist you today?\\n\\t- user: Hello! My name is Jeff.\\n\\t- assistant: Hello, Jeff! How can I assist you today?\\n\\nPlease review the prompt below and answer with \"yes\" if it adheres to the rules or \"no\" if it violates any of the rules.\\nRules:\\n\\t- DENY: ANYTHING about the Titanic. YOU CANNOT talk about the Titanic AT ALL.\\n\\nPrompt:\\nWhen did the Titanic sink?'}]\n",
      "Memory: [{'role': 'system', 'content': 'You are a very helpful and polite chatbot'}, {'role': 'user', 'content': 'Hello! My name is Jeff.'}, {'role': 'assistant', 'content': 'Hello Jeff! How can I assist you today?'}, {'role': 'user', 'content': 'What is my name?'}, {'role': 'assistant', 'content': 'Your name is Jeff.'}, {'role': 'user', 'content': 'When did the Titanic sink?'}, {'role': 'user', 'content': 'Hello! My name is Jeff.'}, {'role': 'assistant', 'content': 'Hello again, Jeff! How can I assist you today?'}, {'role': 'user', 'content': 'Hello! My name is Jeff.'}, {'role': 'assistant', 'content': 'Hello, Jeff! How can I assist you today?'}, {'role': 'user', 'content': 'When did the Titanic sink?'}]\n"
     ]
    }
   ],
   "source": [
    "response = chatbot.chat(\n",
    "    \"When did the Titanic sink?\",\n",
    "    print_cache_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.cache.vector_store.delete(delete_all=True, namespace=\"chatbot-test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
